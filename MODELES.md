# üìö Liste des Mod√®les Disponibles / Available Models

Ce document liste les mod√®les LLM compatibles avec WebLLM que vous pouvez utiliser dans cette application.

This document lists the LLM models compatible with WebLLM that you can use in this application.

## üéØ Mod√®les Recommand√©s / Recommended Models

### 1. **Llama-3.2-1B-Instruct-q4f32_1-MLC** ‚≠ê (Par d√©faut / Default)
- **Taille / Size**: ~650 MB
- **Performance**: Rapide / Fast
- **RAM requise / Required RAM**: 2-3 GB
- **Cas d'usage / Use cases**: 
  - Discussions g√©n√©rales / General conversations
  - Questions-r√©ponses simples / Simple Q&A
  - T√¢ches l√©g√®res / Light tasks
- **Avantages / Advantages**:
  - T√©l√©chargement rapide / Fast download
  - Faible consommation m√©moire / Low memory usage
  - Bonne vitesse d'inf√©rence / Good inference speed

### 2. **Llama-3.2-3B-Instruct-q4f32_1-MLC**
- **Taille / Size**: ~1.9 GB
- **Performance**: √âquilibr√©e / Balanced
- **RAM requise / Required RAM**: 4-5 GB
- **Cas d'usage / Use cases**:
  - T√¢ches complexes / Complex tasks
  - Raisonnement am√©lior√© / Improved reasoning
  - G√©n√©ration de code / Code generation
- **Avantages / Advantages**:
  - Meilleure qualit√© de r√©ponse / Better response quality
  - Plus cr√©atif / More creative
  - Meilleure compr√©hension du contexte / Better context understanding

### 3. **Phi-3.5-mini-instruct-q4f16_1-MLC**
- **Taille / Size**: ~2.2 GB
- **Performance**: Excellente / Excellent
- **RAM requise / Required RAM**: 4-6 GB
- **Cas d'usage / Use cases**:
  - Programmation / Programming
  - Math√©matiques / Mathematics
  - Analyse technique / Technical analysis
- **Avantages / Advantages**:
  - Tr√®s performant pour le code / Excellent for code
  - Bonne pr√©cision / Good accuracy
  - Optimis√© par Microsoft / Optimized by Microsoft

### 4. **Qwen2.5-1.5B-Instruct-q4f16_1-MLC**
- **Taille / Size**: ~950 MB
- **Performance**: Rapide / Fast
- **RAM requise / Required RAM**: 3-4 GB
- **Cas d'usage / Use cases**:
  - Support multilingue / Multilingual support
  - T√¢ches g√©n√©rales / General tasks
- **Avantages / Advantages**:
  - Excellent support des langues asiatiques / Great Asian language support
  - Bon √©quilibre taille/performance / Good size/performance balance

## üîÑ Comment Changer de Mod√®le / How to Change Model

### M√©thode 1: Modifier le code / Edit the code

1. Ouvrez le fichier `/src/lib/stores/llm.svelte.js`
2. Modifiez la ligne `selectedModel` :

```javascript
// Exemple / Example:
selectedModel = $state('Phi-3.5-mini-instruct-q4f16_1-MLC');
```

3. Rechargez l'application / Reload the application

### M√©thode 2: Ajouter un s√©lecteur dans l'UI (TODO)

Vous pouvez am√©liorer l'application en ajoutant un menu d√©roulant pour changer de mod√®le dynamiquement.

You can enhance the application by adding a dropdown menu to change models dynamically.

## üìä Comparaison des Mod√®les / Model Comparison

| Mod√®le / Model | Taille / Size | RAM | Vitesse / Speed | Qualit√© / Quality | Recommand√© pour / Recommended for |
|---|---|---|---|---|---|
| Llama-3.2-1B | 650 MB | 2-3 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | D√©butants / Beginners |
| Llama-3.2-3B | 1.9 GB | 4-5 GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Usage g√©n√©ral / General use |
| Phi-3.5-mini | 2.2 GB | 4-6 GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Code & Tech |
| Qwen2.5-1.5B | 950 MB | 3-4 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Multilingue / Multilingual |

## üîç Autres Mod√®les Disponibles / Other Available Models

Pour voir la liste compl√®te des mod√®les support√©s par WebLLM :
- üîó https://github.com/mlc-ai/web-llm/blob/main/src/config.ts

To see the full list of models supported by WebLLM:
- üîó https://github.com/mlc-ai/web-llm/blob/main/src/config.ts

## ‚öôÔ∏è Quantification Expliqu√©e / Quantization Explained

### Qu'est-ce que la quantification ? / What is quantization?

La quantification r√©duit la taille du mod√®le en utilisant moins de bits pour les poids, ce qui diminue la m√©moire requise et acc√©l√®re l'inf√©rence.

Quantization reduces model size by using fewer bits for weights, which decreases required memory and speeds up inference.

### Types de quantification / Quantization types:

- **q4f32_1**: Poids en 4-bit, calculs en float32
  - Meilleur √©quilibre taille/qualit√© / Best size/quality balance
  - Recommand√© pour la plupart des usages / Recommended for most uses

- **q4f16_1**: Poids en 4-bit, calculs en float16
  - Plus rapide / Faster
  - N√©cessite support GPU / Requires GPU support

- **q0f32**: Pas de quantification
  - Qualit√© maximale / Maximum quality
  - Tr√®s gourmand en m√©moire / Very memory intensive

## üí° Conseils / Tips

### Pour ordinateurs peu puissants / For low-end computers:
- Utilisez Llama-3.2-1B ou Qwen2.5-1.5B / Use Llama-3.2-1B or Qwen2.5-1.5B
- Fermez les autres applications / Close other applications
- Limitez max_tokens √† 256 / Limit max_tokens to 256

### Pour ordinateurs puissants / For powerful computers:
- Essayez Phi-3.5-mini ou Llama-3.2-3B / Try Phi-3.5-mini or Llama-3.2-3B
- Augmentez max_tokens √† 1024+ / Increase max_tokens to 1024+
- Utilisez temperature plus √©lev√©e (0.8-0.9) pour plus de cr√©ativit√© / Use higher temperature (0.8-0.9) for more creativity

## üåê Support des Langues / Language Support

| Mod√®le / Model | Langues support√©es / Supported Languages |
|---|---|
| Llama-3.2-* | Anglais (excellent), Fran√ßais (bon), Espagnol, Allemand, Italien |
| Phi-3.5-mini | Anglais (excellent), Fran√ßais (bon), Code (excellent) |
| Qwen2.5-* | Chinois (excellent), Anglais (excellent), Fran√ßais (bon), autres |

## üìù Notes Importantes / Important Notes

1. **Premier chargement / First load**: Le mod√®le est t√©l√©charg√© une seule fois et mis en cache
2. **Cache navigateur / Browser cache**: Les mod√®les sont stock√©s localement (IndexedDB)
3. **Changement de mod√®le / Model switching**: Efface le cache et ret√©l√©charge le nouveau mod√®le
4. **Performance / Performance**: Varie selon votre mat√©riel (CPU, GPU, RAM)
